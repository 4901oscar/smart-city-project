# üéØ Grafana Consumiendo de Kafka - Gu√≠a Completa

## üìä Arquitectura Implementada

```
Kafka Topics
    ‚îú‚îÄ‚îÄ events.standardized
    ‚îú‚îÄ‚îÄ correlated.alerts
    ‚îî‚îÄ‚îÄ events.dlq
           ‚îÇ
           ‚ñº
    Kafka Exporter (puerto 9308)
           ‚îÇ Exporta m√©tricas
           ‚ñº
    Prometheus (puerto 9090)
           ‚îÇ Scrape cada 15s
           ‚ñº
    Grafana (puerto 3000)
           ‚îÇ Visualiza m√©tricas
           ‚îî‚îÄ‚îÄ Dashboards Auto-provisionados
```

## ‚úÖ ¬øQu√© se ha configurado?

### 1. **Kafka Exporter**
Ya estaba corriendo en tu sistema:
```yaml
kafka-exporter:
  image: danielqsj/kafka-exporter:latest
  ports: "9308:9308"
  environment:
    KAFKA_SERVER: kafka:29092
```

**M√©tricas expuestas:**
- `kafka_topic_partition_current_offset` - Offset actual por topic/partici√≥n
- `kafka_consumergroup_lag` - Lag de consumer groups
- `kafka_topic_partitions` - N√∫mero de particiones
- `kafka_topic_partition_leader` - L√≠der de cada partici√≥n

### 2. **Prometheus**
Configurado para scrapear Kafka Exporter:
```yaml
# monitoring/prometheus/prometheus.yml
scrape_configs:
  - job_name: 'kafka-exporter'
    static_configs:
      - targets: ['kafka-exporter:9308']
```

### 3. **Grafana Datasources (Auto-provisionados)**
Creados en `monitoring/grafana/provisioning/datasources/datasources.yml`:

‚úÖ **Prometheus** (default)
- URL: http://prometheus:9090
- Scrape interval: 15s
- **Uso:** M√©tricas de Kafka

‚úÖ **PostgreSQL**
- Conexi√≥n a Neon Cloud via SSL
- **Uso:** Alertas y eventos persistidos

‚úÖ **Elasticsearch**
- URL: http://elasticsearch:9200
- **Uso:** Logs y b√∫squeda de eventos

### 4. **Dashboards Pre-cargados**

#### Dashboard 1: **Kafka Monitoring**
Archivo: `monitoring/grafana/dashboards/kafka-monitoring.json`

**Paneles:**
1. **Message Rate por Topic** (Time Series)
   - Muestra eventos/segundo en cada topic
   - Query: `rate(kafka_topic_partition_current_offset[5m])`

2. **Consumer Lag** (Gauge)
   - Retraso del consumer en events.standardized
   - Query: `sum(kafka_consumergroup_lag{topic="events.standardized"})`

3. **Messages per Topic/Partition** (Pie Chart)
   - Distribuci√≥n de mensajes
   - Query: `kafka_topic_partition_current_offset`

4. **Topics Status Table** (Table)
   - Estado actual de cada topic/partici√≥n
   - Offset actual por partici√≥n

5. **Consumer Group Lag Timeline** (Time Series)
   - Lag hist√≥rico de cada consumer group
   - Query: `kafka_consumergroup_lag`

#### Dashboard 2: **Alertas Dashboard**
Archivo: `monitoring/grafana/dashboards/alerts-dashboard.json`

**Paneles:**
1. **Total Alertas (24h)** - Stat
2. **Alertas CR√çTICAS (24h)** - Stat con fondo rojo
3. **Score Promedio** - Gauge
4. **Alertas √öltima Hora** - Stat
5. **Timeline de Alertas** - Time Series con todos los tipos
6. **Top 10 Tipos de Alerta** - Donut Chart
7. **Alertas por Zona** - Bar Chart
8. **√öltimas 20 Alertas** - Table con colores por score

---

## üöÄ C√≥mo Acceder

### Paso 1: Abrir Grafana
```
URL: http://localhost:3000/
Usuario: admin
Password: admin
```

### Paso 2: Ver Dashboards
1. Click en el icono de **dashboards** (cuadros apilados) en la barra izquierda
2. Ver√°s la carpeta **Smart City** con 2 dashboards:
   - **Smart City - Kafka Monitoring**
   - **Smart City - Alertas Dashboard**

### Paso 3: Explorar M√©tricas de Kafka

**Dashboard: Kafka Monitoring**

Aqu√≠ ver√°s en tiempo real:
- ‚úÖ Cu√°ntos mensajes/segundo fluyen por cada topic
- ‚úÖ Si el consumer tiene lag (est√° atrasado)
- ‚úÖ Distribuci√≥n de mensajes por partici√≥n
- ‚úÖ Estado de salud de cada topic

**Ejemplo de lo que ver√°s:**
```
events.standardized - partition 0:  500 mensajes
events.standardized - partition 1:  450 mensajes
events.standardized - partition 2:  520 mensajes

Consumer Lag: 0 ‚Üê ‚úÖ Consumer al d√≠a
              50 ‚Üê ‚ö†Ô∏è Consumer atrasado
```

### Paso 4: Explorar Alertas

**Dashboard: Alertas Dashboard**

Ver√°s:
- Total de alertas procesadas
- Cu√°ntas son cr√≠ticas (score = 100)
- Timeline de alertas en las √∫ltimas 24h
- Top tipos de alerta m√°s frecuentes
- Distribuci√≥n por zona

---

## üìä Queries PromQL √ötiles (Kafka)

### Ver eventos/segundo en events.standardized
```promql
rate(kafka_topic_partition_current_offset{topic="events.standardized"}[5m])
```

### Consumer lag total
```promql
sum(kafka_consumergroup_lag)
```

### Consumer lag por topic
```promql
sum by (topic) (kafka_consumergroup_lag)
```

### Total de mensajes en correlated.alerts
```promql
sum(kafka_topic_partition_current_offset{topic="correlated.alerts"})
```

### Particiones con m√°s mensajes
```promql
topk(5, kafka_topic_partition_current_offset)
```

### Alertas en DLQ (eventos fallidos)
```promql
kafka_topic_partition_current_offset{topic="events.dlq"}
```

---

## üé® Crear Panel Personalizado

### Panel: "Eventos en Kafka (√öltimo Minuto)"

1. **Ir al Dashboard** ‚Üí **Add panel**

2. **Configurar Query (Prometheus):**
   ```promql
   sum(rate(kafka_topic_partition_current_offset{topic="events.standardized"}[1m])) * 60
   ```
   
3. **Configuraci√≥n:**
   - Visualization: **Stat**
   - Title: "Eventos/minuto"
   - Unit: Events
   - Color: Value
   - Thresholds:
     - Green: 0-100
     - Yellow: 100-500
     - Red: 500+

4. **Guardar panel**

---

## üìà Panel: "Alertas en Tiempo Real desde Kafka"

Aunque Kafka no persiste alertas (solo las publica), puedes ver:

### Opci√≥n 1: Ver m√©tricas de correlated.alerts

**Query:**
```promql
rate(kafka_topic_partition_current_offset{topic="correlated.alerts"}[5m])
```

**Interpretaci√≥n:**
- Si ves `0.5`, significa 0.5 alertas/segundo = 30 alertas/minuto
- Si ves `0`, no hay alertas gener√°ndose

### Opci√≥n 2: Ver alertas desde PostgreSQL

**Query (PostgreSQL):**
```sql
SELECT 
  created_at AS "time",
  type AS metric,
  score AS value
FROM alerts
WHERE created_at >= NOW() - INTERVAL '5 minutes'
ORDER BY created_at DESC
```

**Visualization:** Table o Time Series

---

## üîî Configurar Alertas en Grafana

### Alerta 1: Consumer Lag Alto

1. **Dashboard** ‚Üí Panel "Consumer Lag" ‚Üí **Alert**

2. **Configurar condici√≥n:**
   ```
   WHEN: last() of query(A)
   IS ABOVE: 100
   FOR: 5m
   ```

3. **Notification:**
   - Contact point: Email/Slack
   - Message: "‚ö†Ô∏è Consumer lag alto: {{$value}} mensajes pendientes"

### Alerta 2: Eventos en DLQ

**Query:**
```promql
kafka_topic_partition_current_offset{topic="events.dlq"}
```

**Condici√≥n:**
```
WHEN: increase() of query(A) over 5m
IS ABOVE: 10
```

**Message:** "üî¥ {{$value}} eventos fallidos en DLQ en los √∫ltimos 5 minutos"

### Alerta 3: No hay eventos nuevos

**Query:**
```promql
rate(kafka_topic_partition_current_offset{topic="events.standardized"}[5m])
```

**Condici√≥n:**
```
WHEN: avg() of query(A)
IS BELOW: 0.01
FOR: 5m
```

**Message:** "‚ö†Ô∏è Sistema no est√° recibiendo eventos (< 1 evento/minuto)"

---

## üéØ Variables de Dashboard

### Variable: Topic Selector

Permite filtrar por topic din√°micamente.

1. **Dashboard Settings** ‚Üí **Variables** ‚Üí **Add variable**

2. **Configurar:**
   ```
   Name: topic
   Type: Query
   Data source: Prometheus
   Query: label_values(kafka_topic_partition_current_offset, topic)
   Multi-value: Yes
   Include All: Yes
   ```

3. **Usar en queries:**
   ```promql
   kafka_topic_partition_current_offset{topic="$topic"}
   ```

### Variable: Consumer Group

```
Name: consumergroup
Type: Query
Data source: Prometheus
Query: label_values(kafka_consumergroup_lag, consumergroup)
```

---

## üìä Ejemplos de Visualizaciones

### 1. Heatmap de Actividad por Hora

**Query (PostgreSQL):**
```sql
SELECT 
  DATE_TRUNC('hour', created_at) AS time,
  COUNT(*) AS value
FROM alerts
WHERE created_at >= NOW() - INTERVAL '7 days'
GROUP BY time
ORDER BY time
```

**Visualization:** Heatmap
- X-axis: Time
- Y-axis: Hour of day
- Color: Number of alerts

### 2. Gauge de Salud del Sistema

**Query (Prometheus):**
```promql
100 - (sum(kafka_consumergroup_lag) / 1000 * 100)
```

**Visualization:** Gauge
- Thresholds:
  - 90-100: Green (Saludable)
  - 70-90: Yellow (Atenci√≥n)
  - 0-70: Red (Cr√≠tico)

### 3. Estad√≠sticas de Eventos por Tipo

**Query (PostgreSQL):**
```sql
SELECT 
  type AS metric,
  COUNT(*) AS total,
  AVG(score) AS avg_score,
  MAX(score) AS max_score
FROM alerts
WHERE created_at >= NOW() - INTERVAL '24 hours'
GROUP BY type
ORDER BY total DESC
```

**Visualization:** Table con columnas coloreadas

---

## üîß Troubleshooting

### No veo datos en Kafka Monitoring

**Verificar:**
```bash
# 1. Kafka Exporter est√° corriendo
docker ps | grep kafka-exporter

# 2. Prometheus puede alcanzar Kafka Exporter
curl http://localhost:9308/metrics

# 3. Prometheus est√° scrapeando
curl http://localhost:9090/api/v1/targets
```

### PostgreSQL datasource no conecta

**Soluci√≥n:**
1. Ir a Configuration ‚Üí Data sources ‚Üí Smart City PostgreSQL
2. Verificar:
   - Host: `<tu-neon-host>:5432`
   - SSL Mode: `require`
   - Password correcta
3. Click "Save & Test"

### Dashboards no aparecen

**Verificar:**
```bash
# Logs de Grafana
docker logs smart-city-project-grafana-1

# Verificar archivos montados
docker exec smart-city-project-grafana-1 ls /etc/grafana/provisioning/datasources
docker exec smart-city-project-grafana-1 ls /var/lib/grafana/dashboards
```

---

## üì± Acceso desde M√≥vil

Grafana es responsive. Accede desde cualquier dispositivo:
```
http://<tu-ip-local>:3000/
```

Para acceso remoto (producci√≥n):
1. Configurar reverse proxy (nginx)
2. Habilitar HTTPS
3. Configurar autenticaci√≥n OAuth

---

## üé® Personalizaci√≥n

### Cambiar Theme
- Profile ‚Üí Preferences ‚Üí UI Theme ‚Üí **Dark** (recomendado para NOC)

### Timezone
- Profile ‚Üí Preferences ‚Üí Timezone ‚Üí **Browser Time** o **America/Guatemala**

### Auto-refresh
- Dashboard ‚Üí Refresh (top right) ‚Üí **5s** para monitoreo en tiempo real

---

## üìä M√©tricas Clave a Monitorear

| M√©trica | Query | Threshold | Acci√≥n |
|---------|-------|-----------|--------|
| Consumer Lag | `sum(kafka_consumergroup_lag)` | > 100 | Escalar consumers |
| Message Rate | `rate(kafka_topic_partition_current_offset[5m])` | < 0.01 | Verificar producer |
| DLQ Size | `kafka_topic_partition_current_offset{topic="events.dlq"}` | > 50 | Revisar validaci√≥n |
| Alertas Cr√≠ticas | `SELECT COUNT(*) FROM alerts WHERE score=100` | > 20/h | Investigar patr√≥n |

---

## üöÄ Pr√≥ximos Pasos

1. **Configurar notificaciones** (Email, Slack, PagerDuty)
2. **Crear alertas autom√°ticas** para m√©tricas cr√≠ticas
3. **Exportar dashboards** a PDF para reportes
4. **Configurar usuarios** con diferentes roles (Viewer, Editor, Admin)
5. **Integrar con Kibana** para an√°lisis de logs

---

## üìù Resumen de URLs

| Servicio | URL | Uso |
|----------|-----|-----|
| Grafana | http://localhost:3000/ | Dashboards y visualizaci√≥n |
| Prometheus | http://localhost:9090/ | Explorar m√©tricas PromQL |
| Kafka Exporter | http://localhost:9308/metrics | Ver m√©tricas raw de Kafka |
| Kafka UI | http://localhost:8080/ | Administrar topics |
| Backend API | http://localhost:5000/ | Ver eventos y alertas |

---

## ‚úÖ Verificaci√≥n Final

Para confirmar que todo funciona:

```bash
# 1. Grafana responde
curl http://localhost:3000/api/health

# 2. Prometheus tiene targets
curl http://localhost:9090/api/v1/targets | grep kafka-exporter

# 3. Dashboards cargados
# Ir a http://localhost:3000/ ‚Üí Dashboards
# Deber√≠as ver "Smart City - Kafka Monitoring"
```

---

**¬°Ahora Grafana est√° consumiendo m√©tricas de Kafka en tiempo real!** üéâ

**Creado:** 2025-10-18  
**Stack:** Kafka Exporter ‚Üí Prometheus ‚Üí Grafana  
**Dashboards:** 2 pre-configurados (Kafka + Alertas)  
**Refresh:** Auto 5s
